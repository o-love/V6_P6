{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addEmojiOverUsersFace(frame, deepFaceObject):\n",
    "    obj = deepFaceObject\n",
    "\n",
    "    print(obj)\n",
    "    region = obj[\"region\"]\n",
    "    top_left = (region[\"x\"], region[\"y\"])\n",
    "    bottom_right = (region[\"x\"] + region[\"w\"], region[\"y\"] + region[\"h\"])\n",
    "    mid_point = tuple(np.array([top_left, bottom_right]).mean(axis=0))\n",
    "\n",
    "    cv2.rectangle(frame, top_left, bottom_right, (0, 255, 0), 2)\n",
    "\n",
    "    base_dir = \"/Users/olove/Programming/Python/OpenCV/VC - ULPGC/P6/assets/\"\n",
    "\n",
    "    emotion = obj[\"dominant_emotion\"]\n",
    "    if emotion == \"happy\":\n",
    "        emoji = u\"\\U0001F600\"\n",
    "        emoji_img = Image.open(base_dir + \"svg/1f600.svg\")\n",
    "    elif emotion == \"sad\":\n",
    "        emoji = u\"\\U0001F614\"\n",
    "        emoji_img = Image.open(base_dir + \"svg/1f614.svg\")\n",
    "    elif emotion == \"angry\":\n",
    "        emoji = u\"\\U0001F620\"\n",
    "        emoji_img = Image.open(base_dir + \"svg/1f620.svg\")\n",
    "    elif emotion == \"neutral\":\n",
    "        emoji = u\"\\U0001F636\"\n",
    "        emoji_img = Image.open(base_dir + \"svg/1f636.svg\")\n",
    "    elif emotion == \"surprise\":\n",
    "        emoji = u\"\\U0001F632\"\n",
    "        emoji_img = Image.open(base_dir + \"svg/1f632.svg\")\n",
    "    elif emotion == \"fear\":\n",
    "        emoji = u\"\\U0001F631\"\n",
    "        emoji_img = Image.open(base_dir + \"svg/1f631.svg\")\n",
    "    elif emotion == \"disgust\":\n",
    "        emoji = u\"\\U0001F922\"\n",
    "        emoji_img = Image.open(base_dir + \"svg/1f922.svg\")\n",
    "    else:\n",
    "        emoji = \"\"\n",
    "\n",
    "    print(emoji)\n",
    "\n",
    "    # Convert frame to PIL image\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(frame_rgb)\n",
    "\n",
    "    emoji_size = (region[\"w\"], region[\"h\"])\n",
    "    emoji_img = emoji_img.resize(emoji_size, Image.ANTIALIAS)\n",
    "\n",
    "            # Overlay the emoji\n",
    "    pil_image.paste(emoji_img, top_left, emoji_img)\n",
    "\n",
    "            # Convert back to OpenCV format\n",
    "    new_frame = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow(\"frame\", new_frame)\n",
    "\n",
    "    return new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 27.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emotion': {'angry': 5.66731550577515e-07, 'disgust': 5.654109697300475e-15, 'fear': 0.40517360903322697, 'happy': 0.016324991884175688, 'sad': 0.0006131358077254845, 'surprise': 0.022459628235083073, 'neutral': 99.5554268360138}, 'dominant_emotion': 'neutral', 'region': {'x': 860, 'y': 217, 'w': 473, 'h': 473}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file '/Users/olove/Programming/Python/OpenCV/VC - ULPGC/P6/assets/svg/1f636.svg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmotion: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m\"\u001b[39m]), (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m250\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     16\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDominant Emotion: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdominant_emotion\u001b[39m\u001b[38;5;124m\"\u001b[39m]), (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m300\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43maddEmojiOverUsersFace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmociones\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Detenemos pulsado ESC\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m, in \u001b[0;36maddEmojiOverUsersFace\u001b[0;34m(frame, deepFaceObject)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m emotion \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     25\u001b[0m     emoji \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\U0001F636\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 26\u001b[0m     emoji_img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msvg/1f636.svg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m emotion \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurprise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     28\u001b[0m     emoji \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\U0001F632\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/VC_P6/lib/python3.11/site-packages/PIL/Image.py:3305\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3303\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[1;32m   3304\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[0;32m-> 3305\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file '/Users/olove/Programming/Python/OpenCV/VC - ULPGC/P6/assets/svg/1f636.svg'"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "# Marca de inicio\n",
    "disponible = 0\n",
    "while (True):\n",
    "    # fotograma a fotograma\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if ret:\n",
    "        obj = DeepFace.analyze(frame,\n",
    "                         enforce_detection=False, actions=['emotion'])\n",
    "\n",
    "        obj = obj[0]\n",
    "\n",
    "        cv2.putText(frame, \"Emotion: \" + str(obj[\"emotion\"]), (10, 250), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"Dominant Emotion: \" + str(obj[\"dominant_emotion\"]), (10, 300), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        frame = addEmojiOverUsersFace(frame, obj)\n",
    "\n",
    "        cv2.imshow(\"Emociones\", frame)\n",
    "\n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
